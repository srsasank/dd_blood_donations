,nrounds = 5000
,nfold = 10
,showsd = T
,stratified = T
,print_every_n = 10
,early_stopping_rounds = 20
,maximize = F,
eval_metric = "logloss"
)
xgb1 <- xgb.train(
params = params
,data = dtrain
,nrounds = 103
,watchlist = list(val=dtest,train=dtrain)
,print_every_n = 10
,early_stopping_rounds = 10
,maximize = F
,eval_metric = "logloss"
)
test$xgbpred <- predict(xgb1,dtest)
write.csv(test,"final_pred2.csv")
cv.ctrl <- trainControl(method = "repeatedcv", repeats = 1,number = 3,
#summaryFunction = twoClassSummary,
classProbs = TRUE,
allowParallel=T)
xgb.grid <- expand.grid(nrounds = 1000,
eta = c(0.01,0.05,0.1),
max_depth = c(2,4,6,8,10,14)
)
set.seed(45)
train_final <- cbind(train_new_data_transformed,train_new_label)
View(train_final)
View(train_final)
set.seed(45)
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="logloss",
nthread =3
)
xgb_tune <-train(factor(result)~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="logloss",
nthread =3
)
xgb_tune <-train(factor(result, levels = 0,1)~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="logloss",
nthread =3
)
train_final$result = as.factor(train_final$result)
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="logloss",
nthread =3
)
View(train_final)
View(train_final)
summary(train_final)
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="Logloss",
nthread =3
)
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
train_final <- cbind(train_new_data_transformed,train_new_label)
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
train_final <- cbind(train_new_data_transformed,train_new_label)
train_final$result <- factor(train_final$result, levels = c("Low","High"))
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
View(train_final)
View(train_final)
train_final$result <- as.factor(train_final$result, levels = c("Low","High"))
train_final <- cbind(train_new_data_transformed,train_new_label)
train_final$result <- as.factor(train_final$result, levels = c("Low","High"))
train_final <- cbind(train_new_data_transformed,train_new_label)
library(magrittr)
train_final$result %<>% factor
levels(train_final$result)
levels(train_final$result) <- c("Low","High")
View(train_final)
View(train_final)
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
cv.ctrl <- trainControl(method = "repeatedcv", repeats = 1,number = 3,
#summaryFunction = twoClassSummary,
classProbs = TRUE,
allowParallel=T)
xgb.grid <- expand.grid(nrounds = 1000,
eta = c(0.01,0.05,0.1),
max_depth = c(2,4,6,8,10,14)
)
set.seed(45)
train_final <- cbind(train_new_data_transformed,train_new_label)
library(magrittr)
train_final$result %<>% factor
levels(train_final$result) <- c("Low","High")
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
cv.ctrl <- trainControl(method = "repeatedcv", repeats = 1,number = 3,
#summaryFunction = twoClassSummary,
classProbs = TRUE,
allowParallel=T)
xgb.grid <- expand.grid(nrounds = 1000,
eta = c(0.01,0.05,0.1),
max_depth = c(2,4,6,8,10,14),
gamma = c(1,2,3,4,5),
min_child_weight=1,
subsample=1,
colsample_bytree=1
)
set.seed(45)
train_final <- cbind(train_new_data_transformed,train_new_label)
library(magrittr)
train_final$result %<>% factor
levels(train_final$result) <- c("Low","High")
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
install.packages("e1071")
library(e1071)
cv.ctrl <- trainControl(method = "repeatedcv", repeats = 1,number = 3,
#summaryFunction = twoClassSummary,
classProbs = TRUE,
allowParallel=T)
xgb.grid <- expand.grid(nrounds = 1000,
eta = c(0.01,0.05,0.1),
max_depth = c(2,4,6,8,10,14),
gamma = c(1,2,3,4,5),
min_child_weight=1,
subsample=1,
colsample_bytree=1
)
set.seed(45)
train_final <- cbind(train_new_data_transformed,train_new_label)
library(magrittr)
train_final$result %<>% factor
levels(train_final$result) <- c("Low","High")
xgb_tune <-train(result~total_volume+freq+first_time+sqrt_recency,
data=train_final,
method="xgbTree",
trControl=cv.ctrl,
tuneGrid=xgb.grid,
verbose=T,
metric="AUC",
nthread =3
)
xgb_tune
xgbpred <- predict(xgb_tune,test_new_data_transformed)
xgbpred <- predict(xgb_tune,test_new_data_transformed, type = "prob")
View(xgbpred)
View(xgbpred)
xgbpred$High
test$high <- xgbpred$High
write.csv(test,"final_pred2.csv")
set.seed(825)
gbmGrid <- expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50, shrinkage = 0.1,
n.minobsinnode = 20)
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "logLoss")
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "logLoss")
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
## Estimate class probabilities
classProbs = TRUE,
## Evaluate performance using
## the following function
summaryFunction = twoClassSummary)
set.seed(825)
gbmGrid <- expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50, shrinkage = 0.1,
n.minobsinnode = 20)
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "logLoss")
gmbFit3
gbmFit3
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "logloss")
gbmFit3
LogLosSummary <- function (data, lev = NULL, model = NULL) {
LogLos <- function(actual, pred, eps = 1e-15) {
stopifnot(all(dim(actual) == dim(pred)))
pred[pred < eps] <- eps
pred[pred > 1 - eps] <- 1 - eps
-sum(actual * log(pred)) / nrow(pred)
}
if (is.character(data$obs)) data$obs <- factor(data$obs, levels = lev)
pred <- data[, "pred"]
obs <- data[, "obs"]
isNA <- is.na(pred)
pred <- pred[!isNA]
obs <- obs[!isNA]
data <- data[!isNA, ]
cls <- levels(obs)
if (length(obs) + length(pred) == 0) {
out <- rep(NA, 2)
} else {
pred <- factor(pred, levels = levels(obs))
require("e1071")
out <- unlist(e1071::classAgreement(table(obs, pred)))[c("diag",                                                                                                                                                             "kappa")]
probs <- data[, cls]
actual <- model.matrix(~ obs - 1)
out2 <- LogLos(actual = actual, pred = probs)
}
out <- c(out, out2)
names(out) <- c("Accuracy", "Kappa", "LogLoss")
if (any(is.nan(out))) out[is.nan(out)] <- NA
out
}
fitControl <- trainControl(method = "repeatedcv",
number = 10,
repeats = 10,
## Estimate class probabilities
classProbs = TRUE,
## Evaluate performance using
## the following function
summaryFunction = LogLosSummary)
set.seed(825)
gbmGrid <- expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50, shrinkage = 0.1,
n.minobsinnode = 20)
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "logloss")
gbmFit3
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "LogLos")
gbmFit3 <- train(result~total_volume+freq+first_time+sqrt_recency, data = train_final, method = "gbm",
trControl = fitControl, verbose = FALSE,
tuneGrid = gbmGrid,
## Specify which metric to optimize
metric = "LogLos")
gbmFit3
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = TRUE,summaryFunction = LogLosSummary,classProbs = TRUE)
mod_fit <- train(result~total_volume+freq+first_time+sqrt_recency,  data=train_final, method="glm", family="binomial",
trControl = ctrl, tuneLength = 5)
mod_fit
pred = predict(mod_fit, newdata=test_new_data_transformed, type = "prob")
View(pred)
View(pred)
test$lgr <- pred$High
write.csv(test,"final_pred2.csv")
write.csv(test,"xgboost/final_pred2.csv")
library(ggplot2)
library(dplyr)
library(caret)
train <- read.csv2("../train.csv",header = TRUE,sep =",")
test <- read.csv2("../test.csv",header = TRUE,sep =",")
colnames(train) <- c("id","month_last","donation_count","total_volume","month_first","result")
colnames(test) <- c("id","month_last","donation_count","total_volume","month_first")
test <-  test %>% mutate(result = 0.5)
train <- train %>% mutate(age = month_first - month_last,
freq = age / donation_count,
log_freq = log(freq+1),
sqrt_freq = sqrt(freq),
donation_score = age * donation_count,
log_score = log(donation_score+1),
first_time = checker(month_first,month_last),
log_recency = log(month_last +1),
sqrt_recency = sqrt(month_last)
)
test <- test %>%  mutate(age = month_first - month_last,
freq = age / donation_count,
log_freq = log(freq+1),
sqrt_freq = sqrt(freq),
donation_score = age * donation_count,
log_score = log(donation_score+1),
first_time = checker(month_first,month_last),
log_recency = log(month_last +1),
sqrt_recency = sqrt(month_last))
train_new <- select(train, -id)
test_new <- select(test, -id)
train_new_data <- select(train_new, - result)
train_new_label <- select(train_new, result)
test_new_data <- select(test_new, - result)
test_new_label <- select(test_new, result)
train_new_data_pp <- preProcess(train_new_data,
method = c("center", "scale", "YeoJohnson", "nzv"))
train_new_data_pp
train_new_data_transformed <- predict(train_new_data_pp, newdata = train_new_data)
test_new_data_pp <- preProcess(test_new_data,
method = c("center", "scale", "YeoJohnson", "nzv"))
test_new_data_transformed <- predict(test_new_data_pp, newdata = test_new_data)
library(data.table)
trainDT <- setDT(train_new_data_transformed)
trainDT2 <- select(trainDT,total_volume,freq,first_time,sqrt_recency)
trainlbl <- setDT(train_new_label)
testDT <- setDT(test_new_data_transformed)
testDT2 <- select(testDT,total_volume,freq,first_time,sqrt_recency)
testlbl <- setDT(test_new_label)
library(ggplot2)
library(dplyr)
library(caret)
train <- read.csv2("../train.csv",header = TRUE,sep =",")
test <- read.csv2("../test.csv",header = TRUE,sep =",")
colnames(train) <- c("id","month_last","donation_count","total_volume","month_first","result")
colnames(test) <- c("id","month_last","donation_count","total_volume","month_first")
test <-  test %>% mutate(result = 0.5)
checker <- function(x,y){
ifelse(x == y,1,0)
}
train <- train %>% mutate(age = month_first - month_last,
freq = age / donation_count,
log_freq = log(freq+1),
sqrt_freq = sqrt(freq),
donation_score = age * donation_count,
log_score = log(donation_score+1),
first_time = checker(month_first,month_last),
log_recency = log(month_last +1),
sqrt_recency = sqrt(month_last)
)
test <- test %>%  mutate(age = month_first - month_last,
freq = age / donation_count,
log_freq = log(freq+1),
sqrt_freq = sqrt(freq),
donation_score = age * donation_count,
log_score = log(donation_score+1),
first_time = checker(month_first,month_last),
log_recency = log(month_last +1),
sqrt_recency = sqrt(month_last))
train_new <- select(train, -id)
test_new <- select(test, -id)
train_new_data <- select(train_new, - result)
train_new_label <- select(train_new, result)
test_new_data <- select(test_new, - result)
test_new_label <- select(test_new, result)
train_new_data_pp <- preProcess(train_new_data,
method = c("center", "scale", "YeoJohnson", "nzv"))
train_new_data_pp
train_new_data_transformed <- predict(train_new_data_pp, newdata = train_new_data)
test_new_data_pp <- preProcess(test_new_data,
method = c("center", "scale", "YeoJohnson", "nzv"))
test_new_data_transformed <- predict(test_new_data_pp, newdata = test_new_data)
View(train_new_data_transformed)
View(train_new_data_transformed)
library(data.table)
trainDT <- setDT(train_new_data_transformed)
trainDT2 <- select(trainDT,total_volume,freq,first_time,sqrt_recency)
trainlbl <- setDT(train_new_label)
testDT <- setDT(test_new_data_transformed)
testDT2 <- select(testDT,total_volume,freq,first_time,sqrt_recency)
testlbl <- setDT(test_new_label)
LogLoss<-function(act, pred)
{
eps = 1e-15;
nr = length(pred)
pred = matrix(sapply( pred, function(x) max(eps,x)), nrow = nr)
pred = matrix(sapply( pred, function(x) min(1-eps,x)), nrow = nr)
ll = sum(act*log(pred) + (1-act)*log(1-pred))
ll = ll * -1/(length(act))
return(ll);
}
plot(c(0,1),c(0,1), col="grey",type="l",xlab = "Mean Prediction",ylab="Observed Fraction")
reliability.plot <- function(obs, pred, bins=10, scale=T) {
# Plots a reliability chart and histogram of a set of predicitons from a classifier
#
# Args:
# obs: Vector of true labels. Should be binary (0 or 1)
# pred: Vector of predictions of each observation from the classifier. Should be real
# number
# bins: The number of bins to use in the reliability plot
# scale: Scale the pred to be between 0 and 1 before creating reliability plot
require(plyr)
library(Hmisc)
min.pred <- min(pred)
max.pred <- max(pred)
min.max.diff <- max.pred - min.pred
if (scale) {
pred <- (pred - min.pred) / min.max.diff
}
bin.pred <- cut(pred, bins)
k <- ldply(levels(bin.pred), function(x) {
idx <- x == bin.pred
c(sum(obs[idx]) / length(obs[idx]), mean(pred[idx]))
})
is.nan.idx <- !is.nan(k$V2)
k <- k[is.nan.idx,]
return(k)
}
train_final <-  cbind(trainDT2,trainlbl)
View(train_final)
View(train_final)
train_final$result <- as.factor(train_final$result)
levels(train_final$result)
levels(train_final$result) <- c("Low","High")
View(train_final)
View(train_final)
test_final <- testDT2
set.seed(221)
sub <- sample(nrow(train_final), floor(nrow(train_final) * 0.85))
training<-train_final[sub,]
cv<-train_final[-sub,]
library(randomForest)
model_rf<-randomForest(result~.,data = training,keep.forest=TRUE,importance=TRUE)
result_cv<-as.data.frame(predict(model_rf,cv,type="prob"))
LogLoss(as.numeric(as.character(cv$Made.Donation.in.March.2007)),result_cv$`1`)
LogLoss(as.numeric(as.character(cv$result)),result_cv$`1`)
result_cv<-as.data.frame(predict(model_rf,cv,type="prob"))
View(result_cv)
View(result_cv)
LogLoss(as.numeric(as.character(cv$result)),result_cv$`High`)
train_final <-  cbind(trainDT2,trainlbl)
train_final$result <- as.factor(train_final$result)
test_final <- testDT2
set.seed(221)
sub <- sample(nrow(train_final), floor(nrow(train_final) * 0.85))
training<-train_final[sub,]
cv<-train_final[-sub,]
library(randomForest)
model_rf<-randomForest(result~.,data = training,keep.forest=TRUE,importance=TRUE)
result_cv<-as.data.frame(predict(model_rf,cv,type="prob"))
LogLoss(as.numeric(as.character(cv$result)),result_cv$`High`)
LogLoss(as.numeric(as.character(cv$result)),result_cv$`1`)
dataframe<-data.frame(result_cv$`1`,cv$Made.Donation.in.March.2007)
dataframe<-data.frame(result_cv$`1`,cv$result)
colnames(dataframe)<-c("x","y")
model_log<-glm(y~x,data = dataframe,family = binomial)
LogLoss(as.numeric(as.character(cv$result)),result_cv_platt)
result_cv_platt<-predict(model_log,dataframe[-2],type = "response")
LogLoss(as.numeric(as.character(cv$result)),result_cv_platt)
k <-reliability.plot(as.numeric(as.character(cv$Made.Donation.in.March.2007)),result_cv$`1`,bins = 5)
install.packages("Hmisc")
k <-reliability.plot(as.numeric(as.character(cv$Made.Donation.in.March.2007)),result_cv$`1`,bins = 5)
lines(k$V2, k$V1, xlim=c(0,1), ylim=c(0,1), xlab="Mean Prediction", ylab="Observed Fraction", col="red", type="o", main="Reliability Plot")
k <-reliability.plot(as.numeric(as.character(cv$result)),result_cv$`1`,bins = 5)
lines(k$V2, k$V1, xlim=c(0,1), ylim=c(0,1), xlab="Mean Prediction", ylab="Observed Fraction", col="red", type="o", main="Reliability Plot")
LogLoss(as.numeric(as.character(cv$result)),result_cv_platt)
result_cv_platt<-predict(model_log,dataframe[-2],type = "response")
dataframe[-2]
